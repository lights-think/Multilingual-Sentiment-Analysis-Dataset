# A High-Quality Multilingual Sentiment Analysis Dataset (EN/ZH)
# ä¸€ä¸ªé«˜è´¨é‡çš„ä¸­è‹±åŒè¯­æƒ…æ„Ÿåˆ†ææ•°æ®é›†

[![License: MIT](https.img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

A high-quality, re-labeled 3-class sentiment analysis dataset containing 100k Chinese (from Weibo) and 100k English (from SST-2, IMDB, Yelp, Amazon) samples. This dataset was created to provide a balanced and more reliable resource for multilingual and cross-lingual sentiment analysis tasks.

è¿™æ˜¯ä¸€ä¸ªé«˜è´¨é‡ã€ç»è¿‡é‡æ–°æ ‡æ³¨çš„ä¸‰åˆ†ç±»æƒ…æ„Ÿåˆ†ææ•°æ®é›†ã€‚å®ƒåŒ…å«10ä¸‡æ¡æ¥è‡ªå¾®åšçš„ä¸­æ–‡æ•°æ®å’Œ10ä¸‡æ¡æ¥è‡ªå¤šä¸ªçŸ¥åè‹±æ–‡æ•°æ®é›†ï¼ˆSST-2, IMDB, Yelp, Amazonï¼‰çš„æ•°æ®ã€‚æœ¬æ•°æ®é›†æ—¨åœ¨ä¸ºå¤šè¯­è¨€å’Œè·¨è¯­è¨€æƒ…æ„Ÿåˆ†æç ”ç©¶æä¾›ä¸€ä¸ªæ›´å‡è¡¡ã€æ›´å¯é çš„èµ„æºã€‚

---

## ğŸŒŸ Introduction | é¡¹ç›®ç®€ä»‹

In the field of Natural Language Processing (NLP), sentiment analysis is a crucial task. However, many existing datasets suffer from noise or annotation inconsistencies. To address this, we developed this multilingual dataset by carefully selecting and re-labeling data from popular sources. The result is a more robust dataset that has demonstrated decent performance in our experiments, making it ideal for training and evaluating modern NLP models.

åœ¨è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰é¢†åŸŸï¼Œæƒ…æ„Ÿåˆ†ææ˜¯ä¸€é¡¹æ ¸å¿ƒä»»åŠ¡ã€‚ç„¶è€Œï¼Œè®¸å¤šç°æœ‰çš„æ•°æ®é›†éƒ½å­˜åœ¨å™ªå£°æˆ–æ ‡æ³¨ä¸ä¸€è‡´çš„é—®é¢˜ã€‚ä¸ºäº†è§£å†³è¿™äº›ç—›ç‚¹ï¼Œæˆ‘ä»¬é€šè¿‡å¯¹å¤šä¸ªä¸»æµæ•°æ®é›†è¿›è¡Œç­›é€‰å’Œé‡æ–°äººå·¥æ ‡æ³¨ï¼Œæ„å»ºäº†è¿™ä¸ªå¤šè¯­è¨€æ•°æ®é›†ã€‚æœ€ç»ˆçš„æ•°æ®é›†åœ¨æˆ‘ä»¬çš„å®éªŒä¸­è¡¨ç°å‡ºè‰¯å¥½çš„æ€§èƒ½ï¼Œéå¸¸é€‚åˆç”¨äºè®­ç»ƒå’Œè¯„ä¼°ç°ä»£NLPæ¨¡å‹ã€‚

## ğŸ“Š Dataset Details | æ•°æ®é›†è¯¦æƒ…

The dataset is divided into two main files: one for English and one for Chinese.

æ•°æ®é›†è¢«åˆ†ä¸ºä¸¤ä¸ªæ–‡ä»¶ï¼šä¸€ä¸ªè‹±æ–‡æ•°æ®é›†ï¼Œä¸€ä¸ªä¸­æ–‡æ•°æ®é›†ã€‚

### English Dataset (`English_Sentiment_3-Class_Dataset.zip`)
* **Note:** This file is in `.zip` format due to its large size. The code example below shows how to load it directly.
* **æ³¨æ„ï¼š** ç”±äºæ–‡ä»¶è¾ƒå¤§ï¼Œæ­¤æ•°æ®é›†ä¸º `.zip` å‹ç¼©æ ¼å¼ã€‚ä¸‹é¢çš„ä»£ç ç¤ºä¾‹å±•ç¤ºäº†å¦‚ä½•ç›´æ¥åŠ è½½å®ƒã€‚
* **Source:** A combination and re-labeling of several famous datasets:
    * [SST-2](https.nlp.stanford.edu/sentiment/index.html) (Stanford Sentiment Treebank)
    * [IMDB Reviews](https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews)
    * [Yelp Reviews](https://www.yelp.com/dataset)
    * [Amazon Review Polarity](https://www.kaggle.com/datasets/bittlingmayer/amazonreviews)
* **Total Samples:** 100,000
* **Language:** English

### Chinese Dataset (`Chinese_Sentiment_3-Class_Dataset.csv`)
* **Source:** Weibo (A major Chinese microblogging platform)
* **Total Samples:** 100,000
* **Language:** Chinese (Simplified)

## ğŸ“ Data Format | æ•°æ®æ ¼å¼

Both CSV files share the same simple structure, with two columns: `data` and `label`.

ä¸¤ä¸ªCSVæ–‡ä»¶éƒ½éµå¾ªç›¸åŒçš„ç»“æ„ï¼ŒåŒ…å«ä¸¤åˆ—ï¼š`data` å’Œ `label`ã€‚

| Column | Description                                    |
| :----- | :--------------------------------------------- |
| `data` | The text content of the review/post. (æ–‡æœ¬å†…å®¹) |
| `label`  | The sentiment label. (æƒ…æ„Ÿæ ‡ç­¾)                 |

### Label Description | æ ‡ç­¾è¯´æ˜
The sentiment is categorized into three classes:
æƒ…æ„Ÿæ ‡ç­¾è¢«åˆ†ä¸ºä»¥ä¸‹ä¸‰ç±»ï¼š

* `0`: Negative (è´Ÿé¢)
* `1`: Neutral (ä¸­æ€§)
* `2`: Positive (æ­£é¢)

***Note:** Please verify if this mapping is correct for your dataset and adjust if necessary. / **æ³¨æ„ï¼š** è¯·æ ¹æ®æ‚¨çš„æ•°æ®é›†ç¡®è®¤æ­¤æ ‡ç­¾æ˜ å°„æ˜¯å¦æ­£ç¡®ï¼Œå¦‚æœ‰éœ€è¦è¯·è‡ªè¡Œè°ƒæ•´ã€‚*

## ğŸš€ Getting Started | å¦‚ä½•ä½¿ç”¨

Here's a simple example of how to load and use the dataset with Python's `pandas` library. The code can directly read the English data from the `.zip` file without manual extraction.

ä¸‹é¢æ˜¯ä¸€ä¸ªä½¿ç”¨ Python `pandas` åº“åŠ è½½å’ŒæŸ¥çœ‹æ•°æ®çš„ç®€å•ç¤ºä¾‹ã€‚è¯¥ä»£ç **æ— éœ€æ‰‹åŠ¨è§£å‹**ï¼Œå³å¯ç›´æ¥ä» `.zip` æ–‡ä»¶ä¸­è¯»å–è‹±æ–‡æ•°æ®ã€‚

```python
import pandas as pd

# Define filenames
# Note: The English dataset is a zip archive.
english_dataset_path = 'English_Sentiment_3-Class_Dataset.zip'
chinese_dataset_path = 'Chinese_Sentiment_3-Class_Dataset.csv'

# Load the datasets
try:
    # Pandas can read directly from a zip file.
    # We assume the csv file inside the zip is named 'English_Sentiment_3-Class_Dataset.csv'
    df_en = pd.read_csv(english_dataset_path)
    df_zh = pd.read_csv(chinese_dataset_path)

    # Display the first 5 rows of the English dataset
    print("--- English Dataset ---")
    print(df_en.head())
    print("\nLabel Distribution:")
    print(df_en['label'].value_counts(normalize=True).sort_index())

    # Display the first 5 rows of the Chinese dataset
    print("\n--- Chinese Dataset ---")
    print(df_zh.head())
    print("\nLabel Distribution:")
    print(df_zh['label'].value_counts(normalize=True).sort_index())

except FileNotFoundError as e:
    print(f"Error: {e}")
    print("Please make sure the dataset files are in the correct directory and named correctly.")
    print("è¯·ç¡®ä¿æ•°æ®é›†æ–‡ä»¶ä½äºæ­£ç¡®çš„ç›®å½•ä¸‹ä¸”æ–‡ä»¶åæ— è¯¯ã€‚")
except Exception as e:
    print(f"An error occurred: {e}")
    print("If you have trouble loading the zip file, ensure it contains one CSV file or specify the filename inside the archive.")
    print("å¦‚æœåŠ è½½zipæ–‡ä»¶æ—¶å‡ºé”™ï¼Œè¯·ç¡®ä¿å‹ç¼©åŒ…å†…åªåŒ…å«ä¸€ä¸ªCSVæ–‡ä»¶ï¼Œæˆ–åœ¨ä»£ç ä¸­æŒ‡å®šå†…éƒ¨çš„æ–‡ä»¶åã€‚")

```

## ğŸ“ˆ Performance | æ€§èƒ½è¡¨ç°

This dataset was used in a graduation project and achieved promising results, demonstrating its quality and utility for sentiment analysis tasks. We encourage you to use it and see how it performs with your models!

æœ¬æ•°æ®é›†å·²åœ¨ä½œè€…çš„æ¯•ä¸šè®¾è®¡ä¸­ä½¿ç”¨ï¼Œå¹¶å–å¾—äº†è‰¯å¥½çš„å®éªŒç»“æœï¼Œè¯æ˜äº†å…¶åœ¨æƒ…æ„Ÿåˆ†æä»»åŠ¡ä¸­çš„é«˜è´¨é‡å’Œå®ç”¨æ€§ã€‚æˆ‘ä»¬éå¸¸æ¬¢è¿æ‚¨ä½¿ç”¨æœ¬æ•°æ®é›†æ¥è®­ç»ƒå’Œæ£€éªŒæ‚¨çš„æ¨¡å‹ï¼

##  citation | å¦‚ä½•å¼•ç”¨

If you use this dataset in your research, please consider citing it. This helps acknowledge the effort and allows others to find the work.

å¦‚æœæ‚¨åœ¨æ‚¨çš„ç ”ç©¶ä¸­ä½¿ç”¨äº†æœ¬æ•°æ®é›†ï¼Œè¯·è€ƒè™‘å¼•ç”¨ã€‚è¿™ä¸ä»…æ˜¯å¯¹æˆ‘ä»¬å·¥ä½œçš„è®¤å¯ï¼Œä¹Ÿèƒ½å¸®åŠ©å…¶ä»–äººå‘ç°è¿™ä»½èµ„æºã€‚

```bibtex
@misc{lights-think_2025_multilingual_sentiment,
  author       = {lights-think},
  title        = {A High-Quality Multilingual Sentiment Analysis Dataset (EN/ZH)},
  month        = jun,
  year         = 2025,
  publisher    = {GitHub},
  howpublished = {\url{[https://github.com/lights-think/Multilingual-Sentiment-Analysis-Dataset](https://github.com/lights-think/Multilingual-Sentiment-Analysis-Dataset)}}
}
```

## ğŸ“„ License | è®¸å¯è¯

This dataset is released under the [MIT License](LICENSE). You are free to use, modify, and distribute it for any purpose, including commercial use.

æœ¬æ•°æ®é›†åŸºäº [MIT è®¸å¯è¯](LICENSE) å‘å¸ƒã€‚æ‚¨å¯ä»¥è‡ªç”±åœ°ä½¿ç”¨ã€ä¿®æ”¹å’Œåˆ†å‘ï¼ŒåŒ…æ‹¬å•†ä¸šç”¨é€”ã€‚

## ğŸ“§ Contact | è”ç³»æ–¹å¼

If you have any questions, suggestions, or find any issues with the dataset, please feel free to open an issue in this repository or contact me at:

* **Email:** `lightsmile7@outlook.com`
* **GitHub:** `lights-think`

å¦‚æœæ‚¨å¯¹æ•°æ®é›†æœ‰ä»»ä½•ç–‘é—®ã€å»ºè®®æˆ–å‘ç°ä»»ä½•é—®é¢˜ï¼Œæ¬¢è¿åœ¨æœ¬ä»“åº“ä¸­æäº¤ Issue æˆ–é€šè¿‡ä»¥ä¸‹æ–¹å¼è”ç³»æˆ‘ï¼š

* **é‚®ç®±:** `lightsmile7@outlook.com`
* **GitHub:** `lights-think`
